{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "local_path = r\"/home/jiajunlong/Data/data/output/random_label_mnist/random_label_mnist_batch1d_sgd_step20_lr0.9_epoch100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在查看目录: /home/jiajunlong/Data/data/output/random_label_mnist/random_label_mnist_batch1d_sgd_step20_lr0.9_epoch100\n"
     ]
    }
   ],
   "source": [
    "monitor_filenames = []\n",
    "train_filenames = []\n",
    "val_filenames = []\n",
    "for dirpath, dirnames, filenames in os.walk(local_path):  \n",
    "    print(f\"正在查看目录: {dirpath}\")  \n",
    "            \n",
    "    # 遍历文件  \n",
    "    for filename in filenames:  \n",
    "        if filename.startswith('monitor'):\n",
    "            monitor_filenames.append(os.path.join(dirpath, filename))\n",
    "        if filename.startswith('train'):\n",
    "            train_filenames.append(os.path.join(dirpath, filename))\n",
    "        if filename.startswith('val'):\n",
    "            val_filenames.append(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_files = []\n",
    "train_files = []\n",
    "val_filens = []\n",
    "for i in monitor_filenames:\n",
    "    with open(i, 'r') as f:\n",
    "        monitor_files.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_WeightNorm': 5.782956600189209,\n",
       " 'linear_InputMean': -0.738074004650116,\n",
       " 'linear_OutputGradSndNorm': 1.703125,\n",
       " 'blocks.0.linear_WeightNorm': 5.7359161376953125,\n",
       " 'blocks.0.linear_InputMean': 0.397216796875,\n",
       " 'blocks.0.linear_OutputGradSndNorm': 1.3857421875,\n",
       " 'blocks.1.linear_WeightNorm': 5.836888790130615,\n",
       " 'blocks.1.linear_InputMean': 0.40087890625,\n",
       " 'blocks.1.linear_OutputGradSndNorm': 1.044921875,\n",
       " 'blocks.2.linear_WeightNorm': 5.742967128753662,\n",
       " 'blocks.2.linear_InputMean': 0.400146484375,\n",
       " 'blocks.2.linear_OutputGradSndNorm': 0.73046875,\n",
       " 'cls_head.linear_WeightNorm': 2.4111416339874268,\n",
       " 'cls_head.linear_InputMean': 0.40478515625,\n",
       " 'cls_head.linear_OutputGradSndNorm': 0.485107421875,\n",
       " 'step': 2700}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(monitor_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_WeightNorm</th>\n",
       "      <th>linear_InputMean</th>\n",
       "      <th>linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.0.linear_WeightNorm</th>\n",
       "      <th>blocks.0.linear_InputMean</th>\n",
       "      <th>blocks.0.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.1.linear_WeightNorm</th>\n",
       "      <th>blocks.1.linear_InputMean</th>\n",
       "      <th>blocks.1.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.2.linear_WeightNorm</th>\n",
       "      <th>blocks.2.linear_InputMean</th>\n",
       "      <th>blocks.2.linear_OutputGradSndNorm</th>\n",
       "      <th>cls_head.linear_WeightNorm</th>\n",
       "      <th>cls_head.linear_InputMean</th>\n",
       "      <th>cls_head.linear_OutputGradSndNorm</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.738074</td>\n",
       "      <td>1.703125</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>1.385742</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.400879</td>\n",
       "      <td>1.044922</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>2.411142</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.485107</td>\n",
       "      <td>2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.782956</td>\n",
       "      <td>-0.737357</td>\n",
       "      <td>0.881836</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>0.709961</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.533691</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399414</td>\n",
       "      <td>0.375244</td>\n",
       "      <td>2.403381</td>\n",
       "      <td>0.404297</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.782940</td>\n",
       "      <td>-0.737390</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>5.735913</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>0.702148</td>\n",
       "      <td>5.836886</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.538086</td>\n",
       "      <td>5.742961</td>\n",
       "      <td>0.399414</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>2.361704</td>\n",
       "      <td>0.403564</td>\n",
       "      <td>0.265381</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.739077</td>\n",
       "      <td>1.632812</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>1.333008</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.401123</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>2.411001</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.473877</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.740917</td>\n",
       "      <td>1.757812</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.396729</td>\n",
       "      <td>1.413086</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>1.060547</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399170</td>\n",
       "      <td>0.745605</td>\n",
       "      <td>2.410518</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.494629</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_WeightNorm  linear_InputMean  linear_OutputGradSndNorm   \n",
       "0           5.782957         -0.738074                  1.703125  \\\n",
       "1           5.782956         -0.737357                  0.881836   \n",
       "2           5.782940         -0.737390                  0.864746   \n",
       "3           5.782957         -0.739077                  1.632812   \n",
       "4           5.782957         -0.740917                  1.757812   \n",
       "\n",
       "   blocks.0.linear_WeightNorm  blocks.0.linear_InputMean   \n",
       "0                    5.735916                   0.397217  \\\n",
       "1                    5.735916                   0.396973   \n",
       "2                    5.735913                   0.396973   \n",
       "3                    5.735916                   0.397461   \n",
       "4                    5.735916                   0.396729   \n",
       "\n",
       "   blocks.0.linear_OutputGradSndNorm  blocks.1.linear_WeightNorm   \n",
       "0                           1.385742                    5.836889  \\\n",
       "1                           0.709961                    5.836889   \n",
       "2                           0.702148                    5.836886   \n",
       "3                           1.333008                    5.836889   \n",
       "4                           1.413086                    5.836889   \n",
       "\n",
       "   blocks.1.linear_InputMean  blocks.1.linear_OutputGradSndNorm   \n",
       "0                   0.400879                           1.044922  \\\n",
       "1                   0.400635                           0.533691   \n",
       "2                   0.400635                           0.538086   \n",
       "3                   0.401123                           1.011719   \n",
       "4                   0.400146                           1.060547   \n",
       "\n",
       "   blocks.2.linear_WeightNorm  blocks.2.linear_InputMean   \n",
       "0                    5.742967                   0.400146  \\\n",
       "1                    5.742967                   0.399414   \n",
       "2                    5.742961                   0.399414   \n",
       "3                    5.742967                   0.400146   \n",
       "4                    5.742967                   0.399170   \n",
       "\n",
       "   blocks.2.linear_OutputGradSndNorm  cls_head.linear_WeightNorm   \n",
       "0                           0.730469                    2.411142  \\\n",
       "1                           0.375244                    2.403381   \n",
       "2                           0.386963                    2.361704   \n",
       "3                           0.712891                    2.411001   \n",
       "4                           0.745605                    2.410518   \n",
       "\n",
       "   cls_head.linear_InputMean  cls_head.linear_OutputGradSndNorm  step  \n",
       "0                   0.404785                           0.485107  2700  \n",
       "1                   0.404297                           0.251221  1440  \n",
       "2                   0.403564                           0.265381   800  \n",
       "3                   0.404785                           0.473877  2500  \n",
       "4                   0.404053                           0.494629  2220  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_files_cpy = monitor_files.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_files_cpy = monitor_files_cpy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_files_cpy[1] = {'step': 20}\n",
    "monitor_files_cpy[1]['test'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(monitor_files_cpy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_WeightNorm</th>\n",
       "      <th>linear_InputMean</th>\n",
       "      <th>linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.0.linear_WeightNorm</th>\n",
       "      <th>blocks.0.linear_InputMean</th>\n",
       "      <th>blocks.0.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.1.linear_WeightNorm</th>\n",
       "      <th>blocks.1.linear_InputMean</th>\n",
       "      <th>blocks.1.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.2.linear_WeightNorm</th>\n",
       "      <th>blocks.2.linear_InputMean</th>\n",
       "      <th>blocks.2.linear_OutputGradSndNorm</th>\n",
       "      <th>cls_head.linear_WeightNorm</th>\n",
       "      <th>cls_head.linear_InputMean</th>\n",
       "      <th>cls_head.linear_OutputGradSndNorm</th>\n",
       "      <th>step</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.738074</td>\n",
       "      <td>1.703125</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>1.385742</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.400879</td>\n",
       "      <td>1.044922</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>2.411142</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.485107</td>\n",
       "      <td>2700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.782940</td>\n",
       "      <td>-0.737390</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>5.735913</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>0.702148</td>\n",
       "      <td>5.836886</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.538086</td>\n",
       "      <td>5.742961</td>\n",
       "      <td>0.399414</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>2.361704</td>\n",
       "      <td>0.403564</td>\n",
       "      <td>0.265381</td>\n",
       "      <td>800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.739077</td>\n",
       "      <td>1.632812</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>1.333008</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.401123</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>2.411001</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.473877</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.740917</td>\n",
       "      <td>1.757812</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.396729</td>\n",
       "      <td>1.413086</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>1.060547</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399170</td>\n",
       "      <td>0.745605</td>\n",
       "      <td>2.410518</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.494629</td>\n",
       "      <td>2220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_WeightNorm  linear_InputMean  linear_OutputGradSndNorm   \n",
       "0           5.782957         -0.738074                  1.703125  \\\n",
       "1                NaN               NaN                       NaN   \n",
       "2           5.782940         -0.737390                  0.864746   \n",
       "3           5.782957         -0.739077                  1.632812   \n",
       "4           5.782957         -0.740917                  1.757812   \n",
       "\n",
       "   blocks.0.linear_WeightNorm  blocks.0.linear_InputMean   \n",
       "0                    5.735916                   0.397217  \\\n",
       "1                         NaN                        NaN   \n",
       "2                    5.735913                   0.396973   \n",
       "3                    5.735916                   0.397461   \n",
       "4                    5.735916                   0.396729   \n",
       "\n",
       "   blocks.0.linear_OutputGradSndNorm  blocks.1.linear_WeightNorm   \n",
       "0                           1.385742                    5.836889  \\\n",
       "1                                NaN                         NaN   \n",
       "2                           0.702148                    5.836886   \n",
       "3                           1.333008                    5.836889   \n",
       "4                           1.413086                    5.836889   \n",
       "\n",
       "   blocks.1.linear_InputMean  blocks.1.linear_OutputGradSndNorm   \n",
       "0                   0.400879                           1.044922  \\\n",
       "1                        NaN                                NaN   \n",
       "2                   0.400635                           0.538086   \n",
       "3                   0.401123                           1.011719   \n",
       "4                   0.400146                           1.060547   \n",
       "\n",
       "   blocks.2.linear_WeightNorm  blocks.2.linear_InputMean   \n",
       "0                    5.742967                   0.400146  \\\n",
       "1                         NaN                        NaN   \n",
       "2                    5.742961                   0.399414   \n",
       "3                    5.742967                   0.400146   \n",
       "4                    5.742967                   0.399170   \n",
       "\n",
       "   blocks.2.linear_OutputGradSndNorm  cls_head.linear_WeightNorm   \n",
       "0                           0.730469                    2.411142  \\\n",
       "1                                NaN                         NaN   \n",
       "2                           0.386963                    2.361704   \n",
       "3                           0.712891                    2.411001   \n",
       "4                           0.745605                    2.410518   \n",
       "\n",
       "   cls_head.linear_InputMean  cls_head.linear_OutputGradSndNorm  step  test  \n",
       "0                   0.404785                           0.485107  2700   NaN  \n",
       "1                        NaN                                NaN    20  10.0  \n",
       "2                   0.403564                           0.265381   800   NaN  \n",
       "3                   0.404785                           0.473877  2500   NaN  \n",
       "4                   0.404053                           0.494629  2220   NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpolated = df.interpolate()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_WeightNorm</th>\n",
       "      <th>linear_InputMean</th>\n",
       "      <th>linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.0.linear_WeightNorm</th>\n",
       "      <th>blocks.0.linear_InputMean</th>\n",
       "      <th>blocks.0.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.1.linear_WeightNorm</th>\n",
       "      <th>blocks.1.linear_InputMean</th>\n",
       "      <th>blocks.1.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.2.linear_WeightNorm</th>\n",
       "      <th>blocks.2.linear_InputMean</th>\n",
       "      <th>blocks.2.linear_OutputGradSndNorm</th>\n",
       "      <th>cls_head.linear_WeightNorm</th>\n",
       "      <th>cls_head.linear_InputMean</th>\n",
       "      <th>cls_head.linear_OutputGradSndNorm</th>\n",
       "      <th>step</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.738074</td>\n",
       "      <td>1.703125</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>1.385742</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.400879</td>\n",
       "      <td>1.044922</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>2.411142</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.485107</td>\n",
       "      <td>2700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.782948</td>\n",
       "      <td>-0.737732</td>\n",
       "      <td>1.283936</td>\n",
       "      <td>5.735915</td>\n",
       "      <td>0.397095</td>\n",
       "      <td>1.043945</td>\n",
       "      <td>5.836888</td>\n",
       "      <td>0.400757</td>\n",
       "      <td>0.791504</td>\n",
       "      <td>5.742964</td>\n",
       "      <td>0.399780</td>\n",
       "      <td>0.558716</td>\n",
       "      <td>2.386423</td>\n",
       "      <td>0.404175</td>\n",
       "      <td>0.375244</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.782940</td>\n",
       "      <td>-0.737390</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>5.735913</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>0.702148</td>\n",
       "      <td>5.836886</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>0.538086</td>\n",
       "      <td>5.742961</td>\n",
       "      <td>0.399414</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>2.361704</td>\n",
       "      <td>0.403564</td>\n",
       "      <td>0.265381</td>\n",
       "      <td>800</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.739077</td>\n",
       "      <td>1.632812</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>1.333008</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.401123</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>2.411001</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.473877</td>\n",
       "      <td>2500</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.740917</td>\n",
       "      <td>1.757812</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.396729</td>\n",
       "      <td>1.413086</td>\n",
       "      <td>5.836889</td>\n",
       "      <td>0.400146</td>\n",
       "      <td>1.060547</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399170</td>\n",
       "      <td>0.745605</td>\n",
       "      <td>2.410518</td>\n",
       "      <td>0.404053</td>\n",
       "      <td>0.494629</td>\n",
       "      <td>2220</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   linear_WeightNorm  linear_InputMean  linear_OutputGradSndNorm   \n",
       "0           5.782957         -0.738074                  1.703125  \\\n",
       "1           5.782948         -0.737732                  1.283936   \n",
       "2           5.782940         -0.737390                  0.864746   \n",
       "3           5.782957         -0.739077                  1.632812   \n",
       "4           5.782957         -0.740917                  1.757812   \n",
       "\n",
       "   blocks.0.linear_WeightNorm  blocks.0.linear_InputMean   \n",
       "0                    5.735916                   0.397217  \\\n",
       "1                    5.735915                   0.397095   \n",
       "2                    5.735913                   0.396973   \n",
       "3                    5.735916                   0.397461   \n",
       "4                    5.735916                   0.396729   \n",
       "\n",
       "   blocks.0.linear_OutputGradSndNorm  blocks.1.linear_WeightNorm   \n",
       "0                           1.385742                    5.836889  \\\n",
       "1                           1.043945                    5.836888   \n",
       "2                           0.702148                    5.836886   \n",
       "3                           1.333008                    5.836889   \n",
       "4                           1.413086                    5.836889   \n",
       "\n",
       "   blocks.1.linear_InputMean  blocks.1.linear_OutputGradSndNorm   \n",
       "0                   0.400879                           1.044922  \\\n",
       "1                   0.400757                           0.791504   \n",
       "2                   0.400635                           0.538086   \n",
       "3                   0.401123                           1.011719   \n",
       "4                   0.400146                           1.060547   \n",
       "\n",
       "   blocks.2.linear_WeightNorm  blocks.2.linear_InputMean   \n",
       "0                    5.742967                   0.400146  \\\n",
       "1                    5.742964                   0.399780   \n",
       "2                    5.742961                   0.399414   \n",
       "3                    5.742967                   0.400146   \n",
       "4                    5.742967                   0.399170   \n",
       "\n",
       "   blocks.2.linear_OutputGradSndNorm  cls_head.linear_WeightNorm   \n",
       "0                           0.730469                    2.411142  \\\n",
       "1                           0.558716                    2.386423   \n",
       "2                           0.386963                    2.361704   \n",
       "3                           0.712891                    2.411001   \n",
       "4                           0.745605                    2.410518   \n",
       "\n",
       "   cls_head.linear_InputMean  cls_head.linear_OutputGradSndNorm  step  test  \n",
       "0                   0.404785                           0.485107  2700   NaN  \n",
       "1                   0.404175                           0.375244    20  10.0  \n",
       "2                   0.403564                           0.265381   800  10.0  \n",
       "3                   0.404785                           0.473877  2500  10.0  \n",
       "4                   0.404053                           0.494629  2220  10.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(monitor_files) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_WeightNorm</th>\n",
       "      <th>linear_InputMean</th>\n",
       "      <th>linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.0.linear_WeightNorm</th>\n",
       "      <th>blocks.0.linear_InputMean</th>\n",
       "      <th>blocks.0.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.1.linear_WeightNorm</th>\n",
       "      <th>blocks.1.linear_InputMean</th>\n",
       "      <th>blocks.1.linear_OutputGradSndNorm</th>\n",
       "      <th>blocks.2.linear_WeightNorm</th>\n",
       "      <th>blocks.2.linear_InputMean</th>\n",
       "      <th>blocks.2.linear_OutputGradSndNorm</th>\n",
       "      <th>cls_head.linear_WeightNorm</th>\n",
       "      <th>cls_head.linear_InputMean</th>\n",
       "      <th>cls_head.linear_OutputGradSndNorm</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.777778</td>\n",
       "      <td>-0.734774</td>\n",
       "      <td>1.478516</td>\n",
       "      <td>5.735047</td>\n",
       "      <td>0.398682</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>5.835851</td>\n",
       "      <td>0.395264</td>\n",
       "      <td>0.860840</td>\n",
       "      <td>5.741453</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>0.723145</td>\n",
       "      <td>1.807132</td>\n",
       "      <td>0.390137</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.777993</td>\n",
       "      <td>-0.737360</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>5.735072</td>\n",
       "      <td>0.397949</td>\n",
       "      <td>1.041992</td>\n",
       "      <td>5.835872</td>\n",
       "      <td>0.394287</td>\n",
       "      <td>0.844727</td>\n",
       "      <td>5.741475</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.709473</td>\n",
       "      <td>1.805703</td>\n",
       "      <td>0.389893</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.778407</td>\n",
       "      <td>-0.737898</td>\n",
       "      <td>1.338867</td>\n",
       "      <td>5.735120</td>\n",
       "      <td>0.398193</td>\n",
       "      <td>0.982910</td>\n",
       "      <td>5.835914</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>0.808594</td>\n",
       "      <td>5.741518</td>\n",
       "      <td>0.392090</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>1.805762</td>\n",
       "      <td>0.390137</td>\n",
       "      <td>0.585449</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.778887</td>\n",
       "      <td>-0.738537</td>\n",
       "      <td>1.288086</td>\n",
       "      <td>5.735179</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>5.835967</td>\n",
       "      <td>0.395752</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>5.741575</td>\n",
       "      <td>0.392578</td>\n",
       "      <td>0.666504</td>\n",
       "      <td>1.808047</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0.573730</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>5.779335</td>\n",
       "      <td>-0.741954</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>5.735239</td>\n",
       "      <td>0.399170</td>\n",
       "      <td>0.907715</td>\n",
       "      <td>5.836024</td>\n",
       "      <td>0.395752</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.741638</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>0.647949</td>\n",
       "      <td>1.812437</td>\n",
       "      <td>0.392090</td>\n",
       "      <td>0.562012</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.739439</td>\n",
       "      <td>1.736328</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>1.417969</td>\n",
       "      <td>5.836888</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>1.076172</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399414</td>\n",
       "      <td>0.756348</td>\n",
       "      <td>2.411255</td>\n",
       "      <td>0.404297</td>\n",
       "      <td>0.502441</td>\n",
       "      <td>2860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.735816</td>\n",
       "      <td>1.731445</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>1.418945</td>\n",
       "      <td>5.836888</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>0.752930</td>\n",
       "      <td>2.411262</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.500488</td>\n",
       "      <td>2870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.739727</td>\n",
       "      <td>1.740234</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>1.405273</td>\n",
       "      <td>5.836888</td>\n",
       "      <td>0.400635</td>\n",
       "      <td>1.065430</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399414</td>\n",
       "      <td>0.747559</td>\n",
       "      <td>2.411269</td>\n",
       "      <td>0.404297</td>\n",
       "      <td>0.498047</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.739445</td>\n",
       "      <td>1.789062</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.396973</td>\n",
       "      <td>1.443359</td>\n",
       "      <td>5.836888</td>\n",
       "      <td>0.401367</td>\n",
       "      <td>1.086914</td>\n",
       "      <td>5.742968</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>0.758789</td>\n",
       "      <td>2.411276</td>\n",
       "      <td>0.405029</td>\n",
       "      <td>0.501465</td>\n",
       "      <td>2890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5.782957</td>\n",
       "      <td>-0.739264</td>\n",
       "      <td>1.762695</td>\n",
       "      <td>5.735916</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>1.426758</td>\n",
       "      <td>5.836888</td>\n",
       "      <td>0.401123</td>\n",
       "      <td>1.068359</td>\n",
       "      <td>5.742967</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>2.411283</td>\n",
       "      <td>0.404297</td>\n",
       "      <td>0.495850</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     linear_WeightNorm  linear_InputMean  linear_OutputGradSndNorm   \n",
       "45            5.777778         -0.734774                  1.478516  \\\n",
       "94            5.777993         -0.737360                  1.437500   \n",
       "54            5.778407         -0.737898                  1.338867   \n",
       "101           5.778887         -0.738537                  1.288086   \n",
       "163           5.779335         -0.741954                  1.230469   \n",
       "..                 ...               ...                       ...   \n",
       "20            5.782957         -0.739439                  1.736328   \n",
       "70            5.782957         -0.735816                  1.731445   \n",
       "226           5.782957         -0.739727                  1.740234   \n",
       "78            5.782957         -0.739445                  1.789062   \n",
       "71            5.782957         -0.739264                  1.762695   \n",
       "\n",
       "     blocks.0.linear_WeightNorm  blocks.0.linear_InputMean   \n",
       "45                     5.735047                   0.398682  \\\n",
       "94                     5.735072                   0.397949   \n",
       "54                     5.735120                   0.398193   \n",
       "101                    5.735179                   0.398438   \n",
       "163                    5.735239                   0.399170   \n",
       "..                          ...                        ...   \n",
       "20                     5.735916                   0.396973   \n",
       "70                     5.735916                   0.396973   \n",
       "226                    5.735916                   0.397217   \n",
       "78                     5.735916                   0.396973   \n",
       "71                     5.735916                   0.397217   \n",
       "\n",
       "     blocks.0.linear_OutputGradSndNorm  blocks.1.linear_WeightNorm   \n",
       "45                            1.072266                    5.835851  \\\n",
       "94                            1.041992                    5.835872   \n",
       "54                            0.982910                    5.835914   \n",
       "101                           0.945312                    5.835967   \n",
       "163                           0.907715                    5.836024   \n",
       "..                                 ...                         ...   \n",
       "20                            1.417969                    5.836888   \n",
       "70                            1.418945                    5.836888   \n",
       "226                           1.405273                    5.836888   \n",
       "78                            1.443359                    5.836888   \n",
       "71                            1.426758                    5.836888   \n",
       "\n",
       "     blocks.1.linear_InputMean  blocks.1.linear_OutputGradSndNorm   \n",
       "45                    0.395264                           0.860840  \\\n",
       "94                    0.394287                           0.844727   \n",
       "54                    0.394531                           0.808594   \n",
       "101                   0.395752                           0.781250   \n",
       "163                   0.395752                           0.750000   \n",
       "..                         ...                                ...   \n",
       "20                    0.400391                           1.076172   \n",
       "70                    0.400635                           1.071289   \n",
       "226                   0.400635                           1.065430   \n",
       "78                    0.401367                           1.086914   \n",
       "71                    0.401123                           1.068359   \n",
       "\n",
       "     blocks.2.linear_WeightNorm  blocks.2.linear_InputMean   \n",
       "45                     5.741453                   0.392578  \\\n",
       "94                     5.741475                   0.391357   \n",
       "54                     5.741518                   0.392090   \n",
       "101                    5.741575                   0.392578   \n",
       "163                    5.741638                   0.392822   \n",
       "..                          ...                        ...   \n",
       "20                     5.742967                   0.399414   \n",
       "70                     5.742967                   0.399902   \n",
       "226                    5.742967                   0.399414   \n",
       "78                     5.742968                   0.400391   \n",
       "71                     5.742967                   0.399902   \n",
       "\n",
       "     blocks.2.linear_OutputGradSndNorm  cls_head.linear_WeightNorm   \n",
       "45                            0.723145                    1.807132  \\\n",
       "94                            0.709473                    1.805703   \n",
       "54                            0.689453                    1.805762   \n",
       "101                           0.666504                    1.808047   \n",
       "163                           0.647949                    1.812437   \n",
       "..                                 ...                         ...   \n",
       "20                            0.756348                    2.411255   \n",
       "70                            0.752930                    2.411262   \n",
       "226                           0.747559                    2.411269   \n",
       "78                            0.758789                    2.411276   \n",
       "71                            0.742676                    2.411283   \n",
       "\n",
       "     cls_head.linear_InputMean  cls_head.linear_OutputGradSndNorm  step  \n",
       "45                    0.390137                           0.604980    10  \n",
       "94                    0.389893                           0.597168    20  \n",
       "54                    0.390137                           0.585449    30  \n",
       "101                   0.391357                           0.573730    40  \n",
       "163                   0.392090                           0.562012    50  \n",
       "..                         ...                                ...   ...  \n",
       "20                    0.404297                           0.502441  2860  \n",
       "70                    0.404785                           0.500488  2870  \n",
       "226                   0.404297                           0.498047  2880  \n",
       "78                    0.405029                           0.501465  2890  \n",
       "71                    0.404297                           0.495850  2900  \n",
       "\n",
       "[290 rows x 16 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = r\"/home/jiajunlong/Data/data/output/random_label_mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_files = [f for f in os.listdir(local_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100',\n",
       " 'random_label_mnist_batch1d_sgd_step30_lr0.9_epoch100',\n",
       " 'random_label_mnist_layer_sgd_step20_lr0.9_epoch100',\n",
       " 'random_label_mnist_none_sgd_step20_lr0.9_epoch100',\n",
       " 'random_label_mnist_batch1d_sgd_step20_lr0.9_epoch100']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTaskData:\n",
    "    def __init__(self, root, task) -> None:\n",
    "        self.task_file_path = os.path.join(root, task)\n",
    "        self.project_filenames = [f for f in os.listdir(self.task_file_path)]\n",
    "        self.project_files_monitor = {}\n",
    "        self.project_files_train = {}\n",
    "        self.project_files_val = {}\n",
    "        \n",
    "    def load_project_data(self):\n",
    "        for project in self.project_filenames:\n",
    "            dataloader = LoadProjectData(self.task_file_path, project)\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "\n",
    "class LoadProjectData:\n",
    "    \n",
    "    def __init__(self, local_path, name) -> None:\n",
    "        self.local_path = os.path.join(local_path, name)\n",
    "        self.monitor_filenames, self.train_filenames, self.val_filenames = self.load_filenames()\n",
    "        self.monitor_data = self.load_filedata(self.monitor_filenames)\n",
    "        self.train_data = self.load_filedata(self.train_filenames)\n",
    "        self.val_data = self.load_filedata(self.val_filenames)\n",
    "   \n",
    "    def load_filenames(self):\n",
    "        local_path = self.local_path\n",
    "        monitor_filenames = []\n",
    "        train_filenames = []\n",
    "        val_filenames = []\n",
    "        for dirpath, dirnames, filenames in os.walk(local_path):  \n",
    "            # print(f\"正在查看目录: {dirpath}\")  \n",
    "            # 遍历文件  \n",
    "            for filename in filenames:  \n",
    "                if filename.startswith('monitor'):\n",
    "                    monitor_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('train'):\n",
    "                    train_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('val'):\n",
    "                    val_filenames.append(os.path.join(dirpath, filename))\n",
    "        return monitor_filenames, train_filenames, val_filenames\n",
    "\n",
    "\n",
    "    def load_filedata(self, filenames):\n",
    "        files = []\n",
    "        for i in filenames:\n",
    "            with open(i, 'r') as f:\n",
    "                files.append(json.load(f))\n",
    "        \n",
    "        df = pd.DataFrame(files) \n",
    "        df = df.sort_values(by='step')\n",
    "        df = df.interpolate()\n",
    "        df = df.dropna()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoadTaskData(root=r\"/home/jiajunlong/Data/data/output\", task=\"random_label_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.load_project_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.project_files_monitor['random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100']\n",
    "data = data.set_index('step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step\n",
       "10     -0.734774\n",
       "11     -0.735032\n",
       "12     -0.735291\n",
       "13     -0.735550\n",
       "14     -0.735808\n",
       "          ...   \n",
       "2896   -0.739336\n",
       "2897   -0.739318\n",
       "2898   -0.739300\n",
       "2899   -0.739282\n",
       "2900   -0.739264\n",
       "Name: linear_InputMean, Length: 2891, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['linear_InputMean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [1, None, 2, 3, None]\n",
    "result = [i for i in result if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LoadTaskData:\n",
    "    def __init__(self, root, task) -> None:\n",
    "        self.task_file_path = os.path.join(root, task)\n",
    "        self.project_filenames = [f for f in os.listdir(self.task_file_path)]\n",
    "        self.project_files_monitor = {}\n",
    "        self.project_files_train = {}\n",
    "        self.project_files_val = {}\n",
    "        self._load_project_data()\n",
    "        \n",
    "    def _load_project_data(self):\n",
    "        for project in self.project_filenames:\n",
    "            dataloader = LoadProjectData(self.task_file_path, project)\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            \n",
    "    def load_monitor_data(self, quantity_name, project_name=None):\n",
    "        data = self.project_files_monitor\n",
    "        if project_name is not None:\n",
    "            project_name = self._get_project_name(project_name)\n",
    "            if isinstance(project_name, str):\n",
    "                data = {project_name: data[project_name]}\n",
    "            elif isinstance(project_name, list):\n",
    "                data = {key: data[key] for key in data if key in project_name} \n",
    "        for key in data:\n",
    "            data[key] = data[key][quantity_name]\n",
    "        return data\n",
    "            \n",
    "                \n",
    "    def _get_project_name(self, project_name):\n",
    "        if isinstance(project_name, str):\n",
    "            project = self.project_files_monitor.get(project_name, None)\n",
    "            if project is not None:\n",
    "                return project_name \n",
    "            else:\n",
    "                return None\n",
    "        if isinstance(project_name, list):\n",
    "            result = [self._get_project_name(i) for i in project_name]\n",
    "            result = [i for i in result if i is not None]\n",
    "            if len(result) == 0:\n",
    "                return None\n",
    "            return result\n",
    "\n",
    "class LoadProjectData:\n",
    "    \n",
    "    def __init__(self, local_path, name) -> None:\n",
    "        self.local_path = os.path.join(local_path, name)\n",
    "        self.monitor_filenames, self.train_filenames, self.val_filenames = self.load_filenames()\n",
    "        self.monitor_data = self.load_filedata(self.monitor_filenames)\n",
    "        self.train_data = self.load_filedata(self.train_filenames)\n",
    "        self.val_data = self.load_filedata(self.val_filenames)\n",
    "   \n",
    "    def load_filenames(self):\n",
    "        local_path = self.local_path\n",
    "        monitor_filenames = []\n",
    "        train_filenames = []\n",
    "        val_filenames = []\n",
    "        for dirpath, dirnames, filenames in os.walk(local_path):  \n",
    "            # print(f\"正在查看目录: {dirpath}\")  \n",
    "            # 遍历文件  \n",
    "            for filename in filenames:  \n",
    "                if filename.startswith('monitor'):\n",
    "                    monitor_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('train'):\n",
    "                    train_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('val'):\n",
    "                    val_filenames.append(os.path.join(dirpath, filename))\n",
    "        return monitor_filenames, train_filenames, val_filenames\n",
    "\n",
    "\n",
    "    def load_filedata(self, filenames):\n",
    "        files = []\n",
    "        for i in filenames:\n",
    "            with open(i, 'r') as f:\n",
    "                files.append(json.load(f))\n",
    "        \n",
    "        df = pd.DataFrame(files) \n",
    "        df = df.sort_values(by='step')\n",
    "        df = df.interpolate()\n",
    "        df = df.dropna()\n",
    "        df = df.set_index('step')\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoadTaskData(root=r\"/home/jiajunlong/Data/data/output\", task=\"random_label_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load_monitor_data('linear_InputMean', 'random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[list(data.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "step\n",
       "10     -0.734774\n",
       "11     -0.735032\n",
       "12     -0.735291\n",
       "13     -0.735550\n",
       "14     -0.735808\n",
       "          ...   \n",
       "2896   -0.739336\n",
       "2897   -0.739318\n",
       "2898   -0.739300\n",
       "2899   -0.739282\n",
       "2900   -0.739264\n",
       "Name: linear_InputMean, Length: 2891, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LoadTaskData:\n",
    "    def __init__(self, root, task) -> None:\n",
    "        self.task_file_path = os.path.join(root, task)\n",
    "        self.project_filenames = [f for f in os.listdir(self.task_file_path)]\n",
    "        self.project_files_monitor = {}\n",
    "        self.project_files_train = {}\n",
    "        self.project_files_val = {}\n",
    "        self._load_project_data()\n",
    "        \n",
    "    def _load_project_data(self):\n",
    "        for project in self.project_filenames:\n",
    "            dataloader = LoadProjectData(self.task_file_path, project)\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            \n",
    "    def load_monitor_data(self, quantity_name, project_name=None):\n",
    "        data = self.project_files_monitor.copy()\n",
    "        if project_name is not None:\n",
    "            project_name = self._get_project_name(project_name)\n",
    "            if isinstance(project_name, str):\n",
    "                data = {project_name: data[project_name]}\n",
    "            elif isinstance(project_name, list):\n",
    "                data = {key: data[key] for key in data if key in project_name} \n",
    "        for key in data:\n",
    "            data[key] = data[key][quantity_name]\n",
    "        return self._extract_quantity_data(data)\n",
    "            \n",
    "                \n",
    "    def _get_project_name(self, project_name):\n",
    "        if isinstance(project_name, str):\n",
    "            project = self.project_files_monitor.get(project_name, None)\n",
    "            if project is not None:\n",
    "                return project_name \n",
    "            else:\n",
    "                return None\n",
    "        if isinstance(project_name, list):\n",
    "            result = [self._get_project_name(i) for i in project_name]\n",
    "            result = [i for i in result if i is not None]\n",
    "            if len(result) == 0:\n",
    "                return None\n",
    "            return result\n",
    "        \n",
    "    def _extract_quantity_data(self, data):\n",
    "        result = {}\n",
    "        result['legend'] = list(data.keys())\n",
    "        x_datas = []\n",
    "        y_datas = []\n",
    "        for i in result['legend']:\n",
    "            df = data[i]\n",
    "            index = df.index\n",
    "            x_datas.append(list(index))\n",
    "            y_datas.append(list(df))\n",
    "        df = data[result['legend'][0]]\n",
    "        result['title'] = df.name\n",
    "        result['x_label'] = df.index.name\n",
    "        result['y_label'] = 'value'    \n",
    "        result['x'] = x_datas\n",
    "        result['y'] = y_datas\n",
    "        return result\n",
    "        \n",
    "\n",
    "class LoadProjectData:\n",
    "    \n",
    "    def __init__(self, local_path, name) -> None:\n",
    "        self.local_path = os.path.join(local_path, name)\n",
    "        self.monitor_filenames, self.train_filenames, self.val_filenames = self.load_filenames()\n",
    "        self.monitor_data = self.load_filedata(self.monitor_filenames)\n",
    "        self.train_data = self.load_filedata(self.train_filenames)\n",
    "        self.val_data = self.load_filedata(self.val_filenames)\n",
    "   \n",
    "    def load_filenames(self):\n",
    "        local_path = self.local_path\n",
    "        monitor_filenames = []\n",
    "        train_filenames = []\n",
    "        val_filenames = []\n",
    "        for dirpath, dirnames, filenames in os.walk(local_path):  \n",
    "            # print(f\"正在查看目录: {dirpath}\")  \n",
    "            # 遍历文件  \n",
    "            for filename in filenames:  \n",
    "                if filename.startswith('monitor'):\n",
    "                    monitor_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('train'):\n",
    "                    train_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('val'):\n",
    "                    val_filenames.append(os.path.join(dirpath, filename))\n",
    "        return monitor_filenames, train_filenames, val_filenames\n",
    "\n",
    "\n",
    "    def load_filedata(self, filenames):\n",
    "        files = []\n",
    "        for i in filenames:\n",
    "            with open(i, 'r') as f:\n",
    "                files.append(json.load(f))\n",
    "        \n",
    "        df = pd.DataFrame(files) \n",
    "        df = df.sort_values(by='step')\n",
    "        df = df.interpolate()\n",
    "        df = df.dropna()\n",
    "        df = df.set_index('step')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoadTaskData(root=r\"/home/jiajunlong/Data/data/output\", task=\"random_label_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load_monitor_data('blocks.2.linear_OutputGradSndNorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 210,\n",
       " 220,\n",
       " 230,\n",
       " 240,\n",
       " 250,\n",
       " 260,\n",
       " 270,\n",
       " 280,\n",
       " 290,\n",
       " 300,\n",
       " 310,\n",
       " 320,\n",
       " 330,\n",
       " 340,\n",
       " 350,\n",
       " 360,\n",
       " 370,\n",
       " 380,\n",
       " 390,\n",
       " 400,\n",
       " 410,\n",
       " 420,\n",
       " 430,\n",
       " 440,\n",
       " 450,\n",
       " 460,\n",
       " 470,\n",
       " 480,\n",
       " 490,\n",
       " 500,\n",
       " 510,\n",
       " 520,\n",
       " 530,\n",
       " 540,\n",
       " 550,\n",
       " 560,\n",
       " 570,\n",
       " 580,\n",
       " 590,\n",
       " 600,\n",
       " 610,\n",
       " 620,\n",
       " 630,\n",
       " 640,\n",
       " 650,\n",
       " 660,\n",
       " 670,\n",
       " 680,\n",
       " 690,\n",
       " 700,\n",
       " 710,\n",
       " 720,\n",
       " 730,\n",
       " 740,\n",
       " 750,\n",
       " 760,\n",
       " 770,\n",
       " 780,\n",
       " 790,\n",
       " 800,\n",
       " 810,\n",
       " 820,\n",
       " 830,\n",
       " 840,\n",
       " 850,\n",
       " 860,\n",
       " 870,\n",
       " 880,\n",
       " 890,\n",
       " 900,\n",
       " 910,\n",
       " 920,\n",
       " 930,\n",
       " 940,\n",
       " 950,\n",
       " 960,\n",
       " 970,\n",
       " 980,\n",
       " 990,\n",
       " 1000,\n",
       " 1010,\n",
       " 1020,\n",
       " 1030,\n",
       " 1040,\n",
       " 1050,\n",
       " 1060,\n",
       " 1070,\n",
       " 1080,\n",
       " 1090,\n",
       " 1100,\n",
       " 1110,\n",
       " 1120,\n",
       " 1130,\n",
       " 1140,\n",
       " 1150,\n",
       " 1160,\n",
       " 1170,\n",
       " 1180,\n",
       " 1190,\n",
       " 1200,\n",
       " 1210,\n",
       " 1220,\n",
       " 1230,\n",
       " 1240,\n",
       " 1250,\n",
       " 1260,\n",
       " 1270,\n",
       " 1280,\n",
       " 1290,\n",
       " 1300,\n",
       " 1310,\n",
       " 1320,\n",
       " 1330,\n",
       " 1340,\n",
       " 1350,\n",
       " 1360,\n",
       " 1370,\n",
       " 1380,\n",
       " 1390,\n",
       " 1400,\n",
       " 1410,\n",
       " 1420,\n",
       " 1430,\n",
       " 1440,\n",
       " 1450,\n",
       " 1460,\n",
       " 1470,\n",
       " 1480,\n",
       " 1490,\n",
       " 1500,\n",
       " 1510,\n",
       " 1520,\n",
       " 1530,\n",
       " 1540,\n",
       " 1550,\n",
       " 1560,\n",
       " 1570,\n",
       " 1580,\n",
       " 1590,\n",
       " 1600,\n",
       " 1610,\n",
       " 1620,\n",
       " 1630,\n",
       " 1640,\n",
       " 1650,\n",
       " 1660,\n",
       " 1670,\n",
       " 1680,\n",
       " 1690,\n",
       " 1700,\n",
       " 1710,\n",
       " 1720,\n",
       " 1730,\n",
       " 1740,\n",
       " 1750,\n",
       " 1760,\n",
       " 1770,\n",
       " 1780,\n",
       " 1790,\n",
       " 1800,\n",
       " 1810,\n",
       " 1820,\n",
       " 1830,\n",
       " 1840,\n",
       " 1850,\n",
       " 1860,\n",
       " 1870,\n",
       " 1880,\n",
       " 1890,\n",
       " 1900,\n",
       " 1910,\n",
       " 1920,\n",
       " 1930,\n",
       " 1940,\n",
       " 1950,\n",
       " 1960,\n",
       " 1970,\n",
       " 1980,\n",
       " 1990,\n",
       " 2000,\n",
       " 2010,\n",
       " 2020,\n",
       " 2030,\n",
       " 2040,\n",
       " 2050,\n",
       " 2060,\n",
       " 2070,\n",
       " 2080,\n",
       " 2090,\n",
       " 2100,\n",
       " 2110,\n",
       " 2120,\n",
       " 2130,\n",
       " 2140,\n",
       " 2150,\n",
       " 2160,\n",
       " 2170,\n",
       " 2180,\n",
       " 2190,\n",
       " 2200,\n",
       " 2210,\n",
       " 2220,\n",
       " 2230,\n",
       " 2240,\n",
       " 2250,\n",
       " 2260,\n",
       " 2270,\n",
       " 2280,\n",
       " 2290,\n",
       " 2300,\n",
       " 2310,\n",
       " 2320,\n",
       " 2330,\n",
       " 2340,\n",
       " 2350,\n",
       " 2360,\n",
       " 2370,\n",
       " 2380,\n",
       " 2390,\n",
       " 2400,\n",
       " 2410,\n",
       " 2420,\n",
       " 2430,\n",
       " 2440,\n",
       " 2450,\n",
       " 2460,\n",
       " 2470,\n",
       " 2480,\n",
       " 2490,\n",
       " 2500,\n",
       " 2510,\n",
       " 2520,\n",
       " 2530,\n",
       " 2540,\n",
       " 2550,\n",
       " 2560,\n",
       " 2570,\n",
       " 2580,\n",
       " 2590,\n",
       " 2600,\n",
       " 2610,\n",
       " 2620,\n",
       " 2630,\n",
       " 2640,\n",
       " 2650,\n",
       " 2660,\n",
       " 2670,\n",
       " 2680,\n",
       " 2690,\n",
       " 2700,\n",
       " 2710,\n",
       " 2720,\n",
       " 2730,\n",
       " 2740,\n",
       " 2750,\n",
       " 2760,\n",
       " 2770,\n",
       " 2780,\n",
       " 2790,\n",
       " 2800,\n",
       " 2810,\n",
       " 2820,\n",
       " 2830,\n",
       " 2840,\n",
       " 2850,\n",
       " 2860,\n",
       " 2870,\n",
       " 2880,\n",
       " 2890,\n",
       " 2900]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTaskData:\n",
    "    def __init__(self, root, task) -> None:\n",
    "        self.task_file_path = os.path.join(root, task)\n",
    "        self.project_filenames = [f for f in os.listdir(self.task_file_path)]\n",
    "        self.project_files_monitor = {}\n",
    "        self.project_files_train = {}\n",
    "        self.project_files_val = {}\n",
    "        self.data = {}\n",
    "        self._load_project_data()\n",
    "        \n",
    "        \n",
    "    def _load_project_data(self):\n",
    "        for project in self.project_filenames:\n",
    "            dataloader = LoadProjectData(self.task_file_path, project)\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_train[project] = dataloader.train_data\n",
    "            self.project_files_val[project] = dataloader.val_data\n",
    "        self.data['monitor'] = self.project_files_monitor\n",
    "        self.data['train'] = self.project_files_train\n",
    "        self.data['val'] = self.project_files_val\n",
    "            \n",
    "    def load_data(self, quantity_name, project_name=None, data_type='monitor'):\n",
    "        data = self.data[data_type].copy()\n",
    "        if project_name is not None:\n",
    "            project_name = self._get_project_name(project_name)\n",
    "            if isinstance(project_name, str):\n",
    "                data = {project_name: data[project_name]}\n",
    "            elif isinstance(project_name, list):\n",
    "                data = {key: data[key] for key in data if key in project_name} \n",
    "        for key in data:\n",
    "            data[key] = data[key][quantity_name]\n",
    "        return self._extract_quantity_data(data)\n",
    "            \n",
    "                \n",
    "    def _get_project_name(self, project_name):\n",
    "        if isinstance(project_name, str):\n",
    "            project = self.project_files_monitor.get(project_name, None)\n",
    "            if project is not None:\n",
    "                return project_name \n",
    "            else:\n",
    "                return None\n",
    "        if isinstance(project_name, list):\n",
    "            result = [self._get_project_name(i) for i in project_name]\n",
    "            result = [i for i in result if i is not None]\n",
    "            if len(result) == 0:\n",
    "                return None\n",
    "            return result\n",
    "        \n",
    "    def _extract_quantity_data(self, data):\n",
    "        result = {}\n",
    "        result['legend'] = list(data.keys())\n",
    "        x_datas = []\n",
    "        y_datas = []\n",
    "        for i in result['legend']:\n",
    "            df = data[i]\n",
    "            index = df.index\n",
    "            x_datas.append(list(index))\n",
    "            y_datas.append(list(df))\n",
    "        df = data[result['legend'][0]]\n",
    "        result['title'] = df.name\n",
    "        result['x_label'] = df.index.name\n",
    "        result['y_label'] = 'value'    \n",
    "        result['x'] = x_datas\n",
    "        result['y'] = y_datas\n",
    "        return result\n",
    "        \n",
    "\n",
    "class LoadProjectData:\n",
    "    \n",
    "    def __init__(self, local_path, name) -> None:\n",
    "        self.local_path = os.path.join(local_path, name)\n",
    "        self.monitor_filenames, self.train_filenames, self.val_filenames = self.load_filenames()\n",
    "        self.monitor_data = self.load_filedata(self.monitor_filenames)\n",
    "        self.train_data = self.load_filedata(self.train_filenames)\n",
    "        self.val_data = self.load_filedata(self.val_filenames)\n",
    "   \n",
    "    def load_filenames(self):\n",
    "        local_path = self.local_path\n",
    "        monitor_filenames = []\n",
    "        train_filenames = []\n",
    "        val_filenames = []\n",
    "        for dirpath, dirnames, filenames in os.walk(local_path):  \n",
    "            # print(f\"正在查看目录: {dirpath}\")  \n",
    "            # 遍历文件  \n",
    "            for filename in filenames:  \n",
    "                if filename.startswith('monitor'):\n",
    "                    monitor_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('train'):\n",
    "                    train_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('val'):\n",
    "                    val_filenames.append(os.path.join(dirpath, filename))\n",
    "        return monitor_filenames, train_filenames, val_filenames\n",
    "\n",
    "\n",
    "    def load_filedata(self, filenames):\n",
    "        files = []\n",
    "        for i in filenames:\n",
    "            with open(i, 'r') as f:\n",
    "                files.append(json.load(f))\n",
    "        \n",
    "        df = pd.DataFrame(files) \n",
    "        df = df.sort_values(by='step')\n",
    "        df = df.interpolate()\n",
    "        df = df.dropna()\n",
    "        df = df.set_index('step')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoadTaskData(root=r\"/home/jiajunlong/Data/data/output\", task=\"random_label_mnist\")\n",
    "data = loader.load_data('blocks.2.linear_OutputGradSndNorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.project_files_monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_WeightNorm\n",
      "linear_InputMean\n",
      "linear_OutputGradSndNorm\n",
      "blocks.0.linear_WeightNorm\n",
      "blocks.0.linear_InputMean\n",
      "blocks.0.linear_OutputGradSndNorm\n",
      "blocks.1.linear_WeightNorm\n",
      "blocks.1.linear_InputMean\n",
      "blocks.1.linear_OutputGradSndNorm\n",
      "blocks.2.linear_WeightNorm\n",
      "blocks.2.linear_InputMean\n",
      "blocks.2.linear_OutputGradSndNorm\n",
      "cls_head.linear_WeightNorm\n",
      "cls_head.linear_InputMean\n",
      "cls_head.linear_OutputGradSndNorm\n"
     ]
    }
   ],
   "source": [
    "for i in data['random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100'].columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Description: \n",
    "@Author: jiajunlong\n",
    "@Date: 2023-12-08 16:37:41\n",
    "@LastEditTime: 2023-12-13 11:05:59\n",
    "@LastEditors: jiajunlong\n",
    "'''\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class LoadTaskData:\n",
    "    def __init__(self, root, task) -> None:\n",
    "        self.task_file_path = os.path.join(root, task)\n",
    "        self.project_filenames = [f for f in os.listdir(self.task_file_path)]\n",
    "        self.project_files_monitor = {}\n",
    "        self.project_files_train = {}\n",
    "        self.project_files_val = {}\n",
    "        self.data = {}\n",
    "        self._load_project_data()\n",
    "        \n",
    "        \n",
    "    def _load_project_data(self):\n",
    "        for project in self.project_filenames:\n",
    "            dataloader = LoadProjectData(self.task_file_path, project)\n",
    "            self.project_files_monitor[project] = dataloader.monitor_data\n",
    "            self.project_files_train[project] = dataloader.train_data\n",
    "            self.project_files_val[project] = dataloader.val_data\n",
    "        self.data['monitor'] = self.project_files_monitor\n",
    "        self.data['train'] = self.project_files_train\n",
    "        self.data['val'] = self.project_files_val\n",
    "            \n",
    "    def load_data(self, quantity_name, project_name=None, data_type='monitor'):\n",
    "        data = self.data[data_type].copy()\n",
    "        if project_name is not None:\n",
    "            project_name = self._get_project_name(project_name)\n",
    "            if isinstance(project_name, str):\n",
    "                data = {project_name: data[project_name]}\n",
    "            elif isinstance(project_name, list):\n",
    "                data = {key: data[key] for key in data if key in project_name} \n",
    "        for key in data:\n",
    "            data[key] = data[key][quantity_name]\n",
    "        return self._extract_quantity_data(data)\n",
    "            \n",
    "                \n",
    "    def _get_project_name(self, project_name):\n",
    "        if isinstance(project_name, str):\n",
    "            project = self.project_files_monitor.get(project_name, None)\n",
    "            if project is not None:\n",
    "                return project_name \n",
    "            else:\n",
    "                return None\n",
    "        if isinstance(project_name, list):\n",
    "            result = [self._get_project_name(i) for i in project_name]\n",
    "            result = [i for i in result if i is not None]\n",
    "            if len(result) == 0:\n",
    "                return None\n",
    "            return result\n",
    "        \n",
    "    def _extract_quantity_data(self, data):\n",
    "        result = {}\n",
    "        result['legend'] = list(data.keys())\n",
    "        x_datas = []\n",
    "        y_datas = []\n",
    "        for i in result['legend']:\n",
    "            df = data[i]\n",
    "            index = df.index\n",
    "            x_datas.append(list(index))\n",
    "            y_datas.append(list(df))\n",
    "        df = data[result['legend'][0]]\n",
    "        result['title'] = df.name\n",
    "        result['x_label'] = df.index.name\n",
    "        result['y_label'] = 'value'    \n",
    "        result['x'] = x_datas\n",
    "        result['y'] = y_datas\n",
    "        return result\n",
    "    \n",
    "    def get_project_name(self):\n",
    "        return self.project_filenames\n",
    "    \n",
    "    def get_quantity_name(self, project_name=None, data_type='monitor'):\n",
    "        data = self.data[data_type].copy()\n",
    "        quantity_data = {}\n",
    "        quantity_name = set()\n",
    "        if project_name is not None:\n",
    "            quantity_data[project_name] = data.get(project_name, None)\n",
    "            if quantity_data[project_name] is None:\n",
    "                quantity_data = data\n",
    "        else:\n",
    "            quantity_data = data\n",
    "        for key in quantity_data:\n",
    "            project_data = quantity_data[key]\n",
    "            for name in project_data.columns:\n",
    "                quantity_name.add(name)\n",
    "        return quantity_name\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "class LoadProjectData:\n",
    "    \n",
    "    def __init__(self, local_path, name) -> None:\n",
    "        self.local_path = os.path.join(local_path, name)\n",
    "        self.monitor_filenames, self.train_filenames, self.val_filenames = self.load_filenames()\n",
    "        self.monitor_data = self.load_filedata(self.monitor_filenames)\n",
    "        self.train_data = self.load_filedata(self.train_filenames)\n",
    "        self.val_data = self.load_filedata(self.val_filenames)\n",
    "   \n",
    "    def load_filenames(self):\n",
    "        local_path = self.local_path\n",
    "        monitor_filenames = []\n",
    "        train_filenames = []\n",
    "        val_filenames = []\n",
    "        for dirpath, dirnames, filenames in os.walk(local_path):  \n",
    "            # print(f\"正在查看目录: {dirpath}\")  \n",
    "            # 遍历文件  \n",
    "            for filename in filenames:  \n",
    "                if filename.startswith('monitor'):\n",
    "                    monitor_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('train'):\n",
    "                    train_filenames.append(os.path.join(dirpath, filename))\n",
    "                if filename.startswith('val'):\n",
    "                    val_filenames.append(os.path.join(dirpath, filename))\n",
    "        return monitor_filenames, train_filenames, val_filenames\n",
    "\n",
    "\n",
    "    def load_filedata(self, filenames):\n",
    "        files = []\n",
    "        for i in filenames:\n",
    "            with open(i, 'r') as f:\n",
    "                files.append(json.load(f))\n",
    "        \n",
    "        df = pd.DataFrame(files) \n",
    "        df = df.sort_values(by='step')\n",
    "        df = df.interpolate()\n",
    "        df = df.dropna()\n",
    "        df = df.set_index('step')\n",
    "        return df\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoadTaskData(root=r\"/home/jiajunlong/Data/data/output\", task=\"random_label_mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100',\n",
       " 'random_label_mnist_batch1d_sgd_step30_lr0.9_epoch100',\n",
       " 'random_label_mnist_layer_sgd_step20_lr0.9_epoch100',\n",
       " 'random_label_mnist_none_sgd_step20_lr0.9_epoch100',\n",
       " 'random_label_mnist_batch1d_sgd_step20_lr0.9_epoch100']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.get_project_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning rate', 'train_accuracy', 'train_loss'}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.get_quantity_name('random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "data = loader.project_files_monitor\n",
    "for i in data['random_label_mnist_batch1d_sgd_step10_lr0.9_epoch100'].columns:\n",
    "    print('blocks.0.linear_WeightNorm' in i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "understandbn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
